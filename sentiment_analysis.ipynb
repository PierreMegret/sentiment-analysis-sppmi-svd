{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: approximating Word2Vec results with SPPMI-SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "Introduced by Mikolov et al. in two papers in 2013 ([[1]](#References) and [[2]](#References)), Word2Vec is a widely popular way of getting vector representation for words. The core assumption of Word2Vec is that if two words are used in similar contexts, then they should share a similar meaning and vector representation. These vector representations can then be used in clustering a set of documents or in text classification tasks.\n",
    "\n",
    "In 2014, Omer Levy and Yoav Goldberg ([[3]](#References)) demonstrated that Word2Vec could be approximated by \"factorizing a word-context matrix whose cells are the pointwise mutual information (PMI) of the respective word and context pairs\". Unlike Word2Vec which is based on a neural-network and uses gradient descent, Omer Levy and Yoav Goldberg method only relies on word count, information theory and the factorization of a matrix with the well-known Singular Value Decomposition. They also go on and show that this method produces word embeddings that can achieve comparable performance as the ones from Word2Vec.\n",
    "\n",
    "In this notebook, I wanted to compare the performance of [Gensim's](https://radimrehurek.com/gensim/models/word2vec.html) famous implementation of Word2Vec and my own implementation of Omer Levy and Yoav Goldberg model on a Sentiment Analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment\n",
    "`python==3.7`<br>\n",
    "`spacy==2.0.12`<br>\n",
    "`nltk==3.4.4`<br>\n",
    "`tqdm=4.32.1`<br>\n",
    "`scikit-learn==0.21.2`<br>\n",
    "`gensim==0.21.2`<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\",\n",
    "                    datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "import spacy \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data\n",
    "\n",
    "\n",
    "The data comes from **Ahmed Besbes** *Sentiment Analysis on twitter using word2vec and keras* blog post \n",
    "[[4]](#References). You can find the data [here](https://drive.google.com/uc?id=0B04GJPshIjmPRnZManQwWEdTZjg&export=download).\n",
    "\n",
    "The data consists of more than a million of tweet, each tweet comes with its content / text and a binary sentiment score (positive / negative feeling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",\n",
    "                        encoding=\"ISO-8859-1\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only the text of the tweets (`msg`) and the sentiment score associated with them (`sentiment`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = df_tweets[[0, 5]]\n",
    "df_tweets.columns = ['sentiment', 'msg']\n",
    "df_tweets['sentiment'] = df_tweets['sentiment'].map({4: 1, 0: 0}) # Mapping 4 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                                msg\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **1,600,000 tweets**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative sentiment example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Just going to cry myself to sleep after watching Marley and Me.  '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets[df_tweets['sentiment'] == 0]['msg'][26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive sentiment example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Just woke up. Having no school is the best feeling ever '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets[df_tweets['sentiment'] == 1]['msg'][1599995]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the distribution of the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a015ea5940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tweets['sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfectly balanced dataset. (\"...As all things should be.\" - Thanos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the number of words in each tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min #words: 1\n",
      "avg #words: 13\n",
      "max #words: 64\n"
     ]
    }
   ],
   "source": [
    "df_len = df_tweets['msg'].str.split().str.len()\n",
    "print(\"min #words: {}\".format(df_len.min()))\n",
    "print(\"avg #words: {}\".format(round(df_len.mean())))\n",
    "print(\"max #words: {}\".format(df_len.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Preprocessing \n",
    "Now, let's do some light preprocessing. We are going to remove hyperlinks, hashtags, and mentions in the tweets, as these do not provide much information for our sentiment analysis task. We will also lowercase the tweets to reduce the size of the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(tweet):\n",
    "    tokens = TweetTokenizer(preserve_case=False,\n",
    "                            reduce_len=True,\n",
    "                            strip_handles=True).tokenize(tweet)\n",
    "    tokens = filter(lambda t: not t.startswith('#'), tokens)\n",
    "    tokens = filter(lambda t: not t.startswith('http'), tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of the `tokenizer()` function in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing:\n",
      "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
      "\n",
      "After preprocessing:\n",
      "- awww , that's a bummer . you shoulda got david carr of third day to do it . ;D\n"
     ]
    }
   ],
   "source": [
    "print('Before preprocessing:')\n",
    "print(df_tweets['msg'][0])\n",
    "print()\n",
    "print('After preprocessing:')\n",
    "print(tokenizer(df_tweets['msg'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's clean-up all the tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcd397501ba4cf7b26b88ab076efe79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='progress-bar', max=1600000, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "df_tweets['clean'] = df_tweets['msg'].progress_map(tokenizer) \n",
    "print(\"{} mins\".format(round((time() - t) / 60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the training & testing sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the preprocessing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many tweets became empty strings after the preprocessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3045"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets[df_tweets['clean'] == '']['sentiment'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not many, we can remove these from the training and testing sets, they won't be useful to our models.\n",
    "\n",
    "Let's have a look at the number of words in each tweets now that we have preprocessed them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.718443125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['len'] = df_tweets['clean'].str.split().str.len()\n",
    "df_tweets['len'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to keep tweets long enough for the word embedding models to learn meaningful information about the words and their context.<br>\n",
    "Let's see how many tweets do we have left if we keep only those with at least 10 words left once preprocessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1088998, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets[df_tweets['len'] >= 10].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That still leaves us plenty of tweets to work with.\n",
    "\n",
    "Does removing empty strings and cleaned up tweets with less than 10 words unbalanced our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a085bdd828>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tweets[(df_tweets['clean'] != '') & (df_tweets['len'] >= 10)]['sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    560114\n",
       "1    528884\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets[(df_tweets['clean'] != '') & (df_tweets['len'] >= 10)]['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9442434932888661"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "528884 / 560114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we remove empty strings and short tweets, our data set is slightly imbalanced, however by only 6%. This is unlikely to introduce much bias to our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sets = df_tweets[(df_tweets['clean'] != '') & (df_tweets['len'] >= 10)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_sets['clean'],\n",
    "                                                    df_sets['sentiment'],\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many elements in the training and testing sets do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871198 871198\n",
      "217800 217800\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0], y_train.shape[0])\n",
    "print(x_test.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Word2Vec and my implementation of SPPMI - SVD requires a list of list of tokens as an input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = x_train.str.split().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec # Gensim's implementation of Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train the model with the default hyperparameters, that should give us decent enough word embeddings.<br>\n",
    "Here's a breakdown of some of the hyperparameters value:\n",
    "* `min_count=5`: every word with an absolute frequency below 5 is ignored\n",
    "* `sample=1e-3`: word with a relative frequency above 0.001 are randomly downsampled\n",
    "* `window=5`: we look at 5 context words to the left of our target word, and 5 context words to the right\n",
    "* `size=100`: the dimension of the resulting word vectors\n",
    "* `negative=5`: negative sampling (For more details, have a look at Chris McCormick [blog post](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/))\n",
    "\n",
    "Training of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:40:07: collecting all words and their counts\n",
      "INFO - 10:40:07: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 10:40:07: PROGRESS: at sentence #10000, processed 188746 words, keeping 15923 word types\n",
      "INFO - 10:40:07: PROGRESS: at sentence #20000, processed 377957 words, keeping 24463 word types\n",
      "INFO - 10:40:07: PROGRESS: at sentence #30000, processed 566253 words, keeping 31333 word types\n",
      "INFO - 10:40:07: PROGRESS: at sentence #40000, processed 754946 words, keeping 37305 word types\n",
      "INFO - 10:40:07: PROGRESS: at sentence #50000, processed 943094 words, keeping 42555 word types\n",
      "INFO - 10:40:07: PROGRESS: at sentence #60000, processed 1131529 words, keeping 47426 word types\n",
      "INFO - 10:40:07: PROGRESS: at sentence #70000, processed 1318966 words, keeping 52175 word types\n",
      "INFO - 10:40:07: PROGRESS: at sentence #80000, processed 1505794 words, keeping 56422 word types\n",
      "INFO - 10:40:07: PROGRESS: at sentence #90000, processed 1695225 words, keeping 60565 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #100000, processed 1883412 words, keeping 64609 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #110000, processed 2072294 words, keeping 68536 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #120000, processed 2259127 words, keeping 72219 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #130000, processed 2446487 words, keeping 75844 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #140000, processed 2634812 words, keeping 79316 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #150000, processed 2823810 words, keeping 82869 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #160000, processed 3011396 words, keeping 86203 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #170000, processed 3198586 words, keeping 89397 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #180000, processed 3386404 words, keeping 92775 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #190000, processed 3574379 words, keeping 95941 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #200000, processed 3762782 words, keeping 99075 word types\n",
      "INFO - 10:40:08: PROGRESS: at sentence #210000, processed 3950755 words, keeping 102181 word types\n",
      "INFO - 10:40:09: PROGRESS: at sentence #220000, processed 4138997 words, keeping 105057 word types\n",
      "INFO - 10:40:09: PROGRESS: at sentence #230000, processed 4326654 words, keeping 107936 word types\n",
      "INFO - 10:40:09: PROGRESS: at sentence #240000, processed 4514776 words, keeping 110793 word types\n",
      "INFO - 10:40:09: PROGRESS: at sentence #250000, processed 4703147 words, keeping 113544 word types\n",
      "INFO - 10:40:09: PROGRESS: at sentence #260000, processed 4890861 words, keeping 116235 word types\n",
      "INFO - 10:40:09: PROGRESS: at sentence #270000, processed 5078871 words, keeping 118928 word types\n",
      "INFO - 10:40:09: PROGRESS: at sentence #280000, processed 5266275 words, keeping 121620 word types\n",
      "INFO - 10:40:09: PROGRESS: at sentence #290000, processed 5453378 words, keeping 124317 word types\n",
      "INFO - 10:40:09: PROGRESS: at sentence #300000, processed 5640972 words, keeping 126938 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #310000, processed 5829436 words, keeping 129453 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #320000, processed 6017339 words, keeping 132144 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #330000, processed 6204754 words, keeping 134612 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #340000, processed 6392279 words, keeping 137088 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #350000, processed 6580265 words, keeping 139443 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #360000, processed 6770044 words, keeping 141989 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #370000, processed 6957408 words, keeping 144303 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #380000, processed 7146576 words, keeping 146707 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #390000, processed 7335543 words, keeping 149052 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #400000, processed 7523880 words, keeping 151425 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #410000, processed 7712610 words, keeping 153621 word types\n",
      "INFO - 10:40:10: PROGRESS: at sentence #420000, processed 7900789 words, keeping 155998 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #430000, processed 8088757 words, keeping 158248 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #440000, processed 8276443 words, keeping 160590 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #450000, processed 8465953 words, keeping 162909 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #460000, processed 8654023 words, keeping 165170 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #470000, processed 8841612 words, keeping 167483 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #480000, processed 9030456 words, keeping 169732 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #490000, processed 9219483 words, keeping 171953 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #500000, processed 9406321 words, keeping 173962 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #510000, processed 9594718 words, keeping 176289 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #520000, processed 9783500 words, keeping 178470 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #530000, processed 9972325 words, keeping 180571 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #540000, processed 10161289 words, keeping 182641 word types\n",
      "INFO - 10:40:11: PROGRESS: at sentence #550000, processed 10349738 words, keeping 184701 word types\n",
      "INFO - 10:40:12: PROGRESS: at sentence #560000, processed 10536829 words, keeping 186714 word types\n",
      "INFO - 10:40:12: PROGRESS: at sentence #570000, processed 10725821 words, keeping 188796 word types\n",
      "INFO - 10:40:12: PROGRESS: at sentence #580000, processed 10914615 words, keeping 190833 word types\n",
      "INFO - 10:40:12: PROGRESS: at sentence #590000, processed 11102438 words, keeping 192855 word types\n",
      "INFO - 10:40:12: PROGRESS: at sentence #600000, processed 11289941 words, keeping 194923 word types\n",
      "INFO - 10:40:12: PROGRESS: at sentence #610000, processed 11479188 words, keeping 196933 word types\n",
      "INFO - 10:40:12: PROGRESS: at sentence #620000, processed 11667774 words, keeping 198907 word types\n",
      "INFO - 10:40:12: PROGRESS: at sentence #630000, processed 11855798 words, keeping 200813 word types\n",
      "INFO - 10:40:12: PROGRESS: at sentence #640000, processed 12044981 words, keeping 202742 word types\n",
      "INFO - 10:40:12: PROGRESS: at sentence #650000, processed 12234807 words, keeping 204750 word types\n",
      "INFO - 10:40:12: PROGRESS: at sentence #660000, processed 12423505 words, keeping 206683 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #670000, processed 12612571 words, keeping 208625 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #680000, processed 12800266 words, keeping 210598 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #690000, processed 12988656 words, keeping 212666 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #700000, processed 13177055 words, keeping 214557 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #710000, processed 13364858 words, keeping 216483 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #720000, processed 13552760 words, keeping 218364 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #730000, processed 13740726 words, keeping 220278 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #740000, processed 13928127 words, keeping 222195 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #750000, processed 14116187 words, keeping 223971 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #760000, processed 14304390 words, keeping 225866 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #770000, processed 14493970 words, keeping 227725 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #780000, processed 14682018 words, keeping 229548 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #790000, processed 14871404 words, keeping 231398 word types\n",
      "INFO - 10:40:13: PROGRESS: at sentence #800000, processed 15060901 words, keeping 233210 word types\n",
      "INFO - 10:40:14: PROGRESS: at sentence #810000, processed 15250445 words, keeping 235117 word types\n",
      "INFO - 10:40:14: PROGRESS: at sentence #820000, processed 15439596 words, keeping 236900 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:40:14: PROGRESS: at sentence #830000, processed 15627848 words, keeping 238737 word types\n",
      "INFO - 10:40:14: PROGRESS: at sentence #840000, processed 15815588 words, keeping 240575 word types\n",
      "INFO - 10:40:14: PROGRESS: at sentence #850000, processed 16004760 words, keeping 242420 word types\n",
      "INFO - 10:40:14: PROGRESS: at sentence #860000, processed 16193495 words, keeping 244202 word types\n",
      "INFO - 10:40:14: PROGRESS: at sentence #870000, processed 16382445 words, keeping 246027 word types\n",
      "INFO - 10:40:14: collected 246248 word types from a corpus of 16405018 raw words and 871198 sentences\n",
      "INFO - 10:40:14: Loading a fresh vocabulary\n",
      "INFO - 10:40:14: effective_min_count=5 retains 44278 unique words (17% of original 246248, drops 201970)\n",
      "INFO - 10:40:14: effective_min_count=5 leaves 16126916 word corpus (98% of original 16405018, drops 278102)\n",
      "INFO - 10:40:14: deleting the raw counts dictionary of 246248 items\n",
      "INFO - 10:40:14: sample=0.001 downsamples 53 most-common words\n",
      "INFO - 10:40:14: downsampling leaves estimated 11966785 word corpus (74.2% of prior 16126916)\n",
      "INFO - 10:40:15: estimated required memory for 44278 words and 100 dimensions: 57561400 bytes\n",
      "INFO - 10:40:15: resetting layer weights\n",
      "INFO - 10:40:15: training model with 3 workers on 44278 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 10:40:16: EPOCH 1 - PROGRESS: at 4.68% examples, 558329 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:17: EPOCH 1 - PROGRESS: at 10.78% examples, 642913 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:40:19: EPOCH 1 - PROGRESS: at 16.39% examples, 649782 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:20: EPOCH 1 - PROGRESS: at 21.58% examples, 639533 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:40:21: EPOCH 1 - PROGRESS: at 28.04% examples, 665285 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:40:22: EPOCH 1 - PROGRESS: at 34.64% examples, 683883 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:23: EPOCH 1 - PROGRESS: at 41.22% examples, 697633 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:24: EPOCH 1 - PROGRESS: at 47.00% examples, 695730 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:25: EPOCH 1 - PROGRESS: at 52.72% examples, 694373 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:40:26: EPOCH 1 - PROGRESS: at 58.82% examples, 697461 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:27: EPOCH 1 - PROGRESS: at 65.15% examples, 702769 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:28: EPOCH 1 - PROGRESS: at 71.66% examples, 708996 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:29: EPOCH 1 - PROGRESS: at 78.22% examples, 714562 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:30: EPOCH 1 - PROGRESS: at 84.44% examples, 716073 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:31: EPOCH 1 - PROGRESS: at 90.28% examples, 714752 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:40:32: EPOCH 1 - PROGRESS: at 95.31% examples, 707780 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 10:40:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:40:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:40:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:40:32: EPOCH - 1 : training on 16405018 raw words (11967093 effective words) took 17.0s, 703558 effective words/s\n",
      "INFO - 10:40:34: EPOCH 2 - PROGRESS: at 5.16% examples, 615421 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:35: EPOCH 2 - PROGRESS: at 10.11% examples, 601592 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:36: EPOCH 2 - PROGRESS: at 14.87% examples, 589656 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:37: EPOCH 2 - PROGRESS: at 18.83% examples, 559776 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:40:38: EPOCH 2 - PROGRESS: at 23.65% examples, 562072 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:39: EPOCH 2 - PROGRESS: at 28.89% examples, 572341 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:40: EPOCH 2 - PROGRESS: at 34.88% examples, 591817 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 10:40:41: EPOCH 2 - PROGRESS: at 41.22% examples, 612186 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:42: EPOCH 2 - PROGRESS: at 47.43% examples, 626573 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:40:43: EPOCH 2 - PROGRESS: at 53.70% examples, 638132 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:44: EPOCH 2 - PROGRESS: at 59.67% examples, 645033 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:45: EPOCH 2 - PROGRESS: at 66.05% examples, 654545 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:46: EPOCH 2 - PROGRESS: at 72.08% examples, 659626 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:47: EPOCH 2 - PROGRESS: at 78.40% examples, 666350 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:48: EPOCH 2 - PROGRESS: at 84.68% examples, 671813 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:49: EPOCH 2 - PROGRESS: at 90.76% examples, 675279 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:40:50: EPOCH 2 - PROGRESS: at 97.01% examples, 679601 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:40:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:40:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:40:50: EPOCH - 2 : training on 16405018 raw words (11967389 effective words) took 17.6s, 681384 effective words/s\n",
      "INFO - 10:40:51: EPOCH 3 - PROGRESS: at 6.08% examples, 725763 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:52: EPOCH 3 - PROGRESS: at 12.36% examples, 735609 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:53: EPOCH 3 - PROGRESS: at 17.97% examples, 713749 words/s, in_qsize 5, out_qsize 1\n",
      "INFO - 10:40:54: EPOCH 3 - PROGRESS: at 23.35% examples, 692787 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:40:55: EPOCH 3 - PROGRESS: at 28.83% examples, 685040 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:56: EPOCH 3 - PROGRESS: at 34.46% examples, 682608 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:40:57: EPOCH 3 - PROGRESS: at 38.12% examples, 645650 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 10:40:58: EPOCH 3 - PROGRESS: at 41.59% examples, 616475 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:40:59: EPOCH 3 - PROGRESS: at 47.12% examples, 620702 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:00: EPOCH 3 - PROGRESS: at 53.15% examples, 630225 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:01: EPOCH 3 - PROGRESS: at 58.63% examples, 632393 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:02: EPOCH 3 - PROGRESS: at 63.50% examples, 626505 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 10:41:03: EPOCH 3 - PROGRESS: at 68.74% examples, 626316 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:04: EPOCH 3 - PROGRESS: at 72.14% examples, 610157 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 10:41:05: EPOCH 3 - PROGRESS: at 74.93% examples, 591714 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:06: EPOCH 3 - PROGRESS: at 78.95% examples, 584478 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:07: EPOCH 3 - PROGRESS: at 82.48% examples, 574590 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:08: EPOCH 3 - PROGRESS: at 86.76% examples, 570883 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:09: EPOCH 3 - PROGRESS: at 91.00% examples, 566928 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 10:41:10: EPOCH 3 - PROGRESS: at 95.92% examples, 567332 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:11: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:41:11: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:41:11: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:41:11: EPOCH - 3 : training on 16405018 raw words (11967273 effective words) took 21.0s, 570410 effective words/s\n",
      "INFO - 10:41:12: EPOCH 4 - PROGRESS: at 5.41% examples, 637573 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:13: EPOCH 4 - PROGRESS: at 8.65% examples, 511523 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:14: EPOCH 4 - PROGRESS: at 11.63% examples, 458554 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:15: EPOCH 4 - PROGRESS: at 16.20% examples, 479530 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:16: EPOCH 4 - PROGRESS: at 19.56% examples, 462453 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:17: EPOCH 4 - PROGRESS: at 24.26% examples, 478485 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:18: EPOCH 4 - PROGRESS: at 28.59% examples, 482096 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:41:19: EPOCH 4 - PROGRESS: at 33.66% examples, 497014 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:20: EPOCH 4 - PROGRESS: at 38.42% examples, 503828 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:21: EPOCH 4 - PROGRESS: at 43.47% examples, 513711 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:22: EPOCH 4 - PROGRESS: at 49.13% examples, 527947 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:23: EPOCH 4 - PROGRESS: at 54.80% examples, 540036 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:24: EPOCH 4 - PROGRESS: at 60.82% examples, 553277 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:25: EPOCH 4 - PROGRESS: at 67.09% examples, 567057 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:26: EPOCH 4 - PROGRESS: at 73.30% examples, 578671 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:27: EPOCH 4 - PROGRESS: at 77.97% examples, 577312 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:28: EPOCH 4 - PROGRESS: at 83.95% examples, 584756 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:29: EPOCH 4 - PROGRESS: at 88.58% examples, 582973 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:30: EPOCH 4 - PROGRESS: at 92.64% examples, 577813 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:31: EPOCH 4 - PROGRESS: at 96.65% examples, 572423 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:41:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:41:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:41:32: EPOCH - 4 : training on 16405018 raw words (11963623 effective words) took 21.0s, 568790 effective words/s\n",
      "INFO - 10:41:33: EPOCH 5 - PROGRESS: at 2.12% examples, 246493 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:34: EPOCH 5 - PROGRESS: at 4.62% examples, 265036 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:35: EPOCH 5 - PROGRESS: at 7.30% examples, 280776 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 10:41:36: EPOCH 5 - PROGRESS: at 9.62% examples, 278421 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:37: EPOCH 5 - PROGRESS: at 12.48% examples, 290857 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:38: EPOCH 5 - PROGRESS: at 14.87% examples, 288498 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:39: EPOCH 5 - PROGRESS: at 17.12% examples, 285447 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:40: EPOCH 5 - PROGRESS: at 20.00% examples, 291813 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:41: EPOCH 5 - PROGRESS: at 23.04% examples, 299583 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 10:41:42: EPOCH 5 - PROGRESS: at 26.09% examples, 304996 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:43: EPOCH 5 - PROGRESS: at 28.77% examples, 305646 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:44: EPOCH 5 - PROGRESS: at 31.34% examples, 305278 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:45: EPOCH 5 - PROGRESS: at 34.64% examples, 311714 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:46: EPOCH 5 - PROGRESS: at 38.05% examples, 318153 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:48: EPOCH 5 - PROGRESS: at 41.89% examples, 326509 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:49: EPOCH 5 - PROGRESS: at 45.54% examples, 332887 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 10:41:50: EPOCH 5 - PROGRESS: at 48.89% examples, 336422 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:51: EPOCH 5 - PROGRESS: at 51.75% examples, 335829 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:52: EPOCH 5 - PROGRESS: at 54.68% examples, 336477 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:53: EPOCH 5 - PROGRESS: at 57.17% examples, 334411 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:54: EPOCH 5 - PROGRESS: at 59.30% examples, 330679 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:55: EPOCH 5 - PROGRESS: at 61.91% examples, 329764 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:56: EPOCH 5 - PROGRESS: at 64.11% examples, 326458 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:57: EPOCH 5 - PROGRESS: at 67.58% examples, 329820 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:41:58: EPOCH 5 - PROGRESS: at 70.87% examples, 332234 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:41:59: EPOCH 5 - PROGRESS: at 72.21% examples, 325442 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:42:00: EPOCH 5 - PROGRESS: at 74.69% examples, 324207 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 10:42:01: EPOCH 5 - PROGRESS: at 78.64% examples, 329221 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:42:02: EPOCH 5 - PROGRESS: at 81.39% examples, 328967 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:42:03: EPOCH 5 - PROGRESS: at 82.55% examples, 321597 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:42:04: EPOCH 5 - PROGRESS: at 83.70% examples, 315692 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:42:05: EPOCH 5 - PROGRESS: at 86.94% examples, 317800 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 10:42:06: EPOCH 5 - PROGRESS: at 91.06% examples, 322845 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:42:07: EPOCH 5 - PROGRESS: at 94.46% examples, 325266 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 10:42:08: EPOCH 5 - PROGRESS: at 98.54% examples, 329530 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 10:42:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:42:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:42:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:42:08: EPOCH - 5 : training on 16405018 raw words (11967189 effective words) took 36.2s, 330354 effective words/s\n",
      "INFO - 10:42:08: training on a 82025090 raw words (59832567 effective words) took 113.0s, 529703 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 2.03 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "model_w2v = Word2Vec(sentences, workers=3)\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the model quickly:\n",
    "\n",
    "* which words are closest to *tweet*, *happy*, and *sad*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:44:43: precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('reply', 0.767540454864502), ('message', 0.7159344553947449), ('twit', 0.6866358518600464), ('post', 0.678138017654419), ('text', 0.6508252620697021)]\n",
      "\n",
      "happy\n",
      "[('pleased', 0.6360591053962708), ('thrilled', 0.6244389414787292), ('happpy', 0.6203890442848206), ('thankful', 0.6077747941017151), ('blessed', 0.5924043655395508)]\n",
      "\n",
      "sad\n",
      "[('upset', 0.766880214214325), ('depressed', 0.746283233165741), ('bummed', 0.7132532000541687), ('disappointed', 0.7101408243179321), ('saddd', 0.7009017467498779)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in ['tweet', 'happy', 'sad']:\n",
    "    print(x)\n",
    "    print(model_w2v.wv.most_similar(positive=x, topn=5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How similar are *sad* and *joy*? *Sad* and *unhappy*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002171792"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.similarity(w1='sad', w2='joy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6453774"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.similarity(w1='sad', w2='unhappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which of *phone*, *iphone*, and *dentist*, is the odd-one-out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'banana'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.doesnt_match(['phone', 'iphone', 'banana'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model and the model's word vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:46:04: saving Word2Vec object under models\\model_w2v.w2v, separately None\n",
      "INFO - 10:46:04: not storing attribute vectors_norm\n",
      "INFO - 10:46:04: not storing attribute cum_table\n",
      "INFO - 10:46:06: saved models\\model_w2v.w2v\n"
     ]
    }
   ],
   "source": [
    "model_w2v.save('models\\model_w2v.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:46:08: storing 44278x100 projection weights into models\\model_w2v.vectors\n"
     ]
    }
   ],
   "source": [
    "model_w2v.wv.save_word2vec_format(fname='models\\model_w2v.vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPPMI - SVD: an alternative to Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 2014 research paper by Omer Levy and Yoav Goldberg *Neural Word Embedding as Implicit Matrix Factorization* [[3]](#References), in the 2016 blog post by Sebastian Ruder *On word embeddings - Part 3: The secret ingredients of word2vec* [[5]](#References), and in the 2017 blog post of Chris Moody *Stop Using Word2Vec* [[6]](#References), an alternative to Word2Vec is outlined in order to get vector representation of words. Instead of using a shallow neural network and a cost function optimization, this approach only uses word co-occurences, information theory and matrix factorization.\n",
    "\n",
    "In a nutshell, PMI - SVD can be summed up in 5 steps:\n",
    "1. Collecting the frequency of each word in the corpus\n",
    "2. Calculating the probability for word1 to been seen next to word2 (co-occurence matrix)\n",
    "3. Calculating the Pointwise Mutual Information (PMI) of word1 and word2. In the information theory field, this represents how often word1 and word2 are associated together\n",
    "4. Reducing the dimension of the PMI matrix with a Singular Value Decomposition.\n",
    "\n",
    "I added some steps in my implementation of the method, namely:\n",
    "1. **Minimum Count**: ignoring words below a certain frequency, if a word only appears once or twice in more than 1 million tweets, we won't be able to learn a useful embedding for it.\n",
    "2. **Downsampling**: just like for Word2Vec, this step reduces the influence of higher-frequency words, such as \"the\", \"she\", \"have\", etc. \n",
    "3. **Shifted Positive PMI (SPPMI)**: offsetting the PMI of two words by a constant, this is equivalent to Word2Vec negative sampling. (Referenced both in Omer Levy and Yoav Goldberg research paper [[4]](#References) and in Sebastian Ruder's [blog post](http://ruder.io/secret-word2vec/index.html#shiftedpmi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a SPPMI - SVD model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my own implementation of a SPPMI - SVD model in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pierre_sppmi_svd.sppmi_svd import SPPMI_SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model with the same hyperparameters as the one used in the Word2Vec model.<br>\n",
    "An explanation of the other parameters:\n",
    "* `context_alpha=0.75`: How negative samples are drawn from the corpus (cf. Sebastian Ruder's [blog post](http://ruder.io/secret-word2vec/index.html#contextdistributionsmoothing)). Empirically set to 0.75 by Mikolov et al. in their 2013 paper *Distributed Representations of Words and Phrases and their Compositionality* [[2]](#References)\n",
    "* `filename`: I added some built-in functions to save a model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:46:55: Starting the creation of the model.\n",
      "INFO - 10:46:55: Starting unigrams count.\n",
      "INFO - 10:46:55: PROGRESS: at sentence #0, processed 0 words, keeping 0 unique word\n",
      "INFO - 10:46:57: PROGRESS: at sentence #100000, processed 64609 words, keeping 64609 unique word\n",
      "INFO - 10:46:58: PROGRESS: at sentence #200000, processed 99075 words, keeping 99075 unique word\n",
      "INFO - 10:46:59: PROGRESS: at sentence #300000, processed 126938 words, keeping 126938 unique word\n",
      "INFO - 10:47:00: PROGRESS: at sentence #400000, processed 151425 words, keeping 151425 unique word\n",
      "INFO - 10:47:01: PROGRESS: at sentence #500000, processed 173962 words, keeping 173962 unique word\n",
      "INFO - 10:47:02: PROGRESS: at sentence #600000, processed 194923 words, keeping 194923 unique word\n",
      "INFO - 10:47:03: PROGRESS: at sentence #700000, processed 214557 words, keeping 214557 unique word\n",
      "INFO - 10:47:04: PROGRESS: at sentence #800000, processed 233210 words, keeping 233210 unique word\n",
      "INFO - 10:47:05: Ending unigrams count.\n",
      "INFO - 10:47:05: collected 246248 word types from a corpus of 246248 raw words and 871197 sentences\n",
      "INFO - 10:47:05: 246248 tokens before min_count=5\n",
      "INFO - 10:47:05: 246248 tokens after min_count=5\n",
      "INFO - 10:47:06: sample=0.001 downsamples 51 most-common words and leaves 246197 untouched\n",
      "INFO - 10:47:06: downsampling leaves estimated 12278926 word corpus (74.85% of prior 16405018)\n",
      "INFO - 10:47:06: Starting the co-occurence count.\n",
      "INFO - 10:47:06: PROGRESS: processing sentence #0\n",
      "INFO - 10:47:32: PROGRESS: processing sentence #100000\n",
      "INFO - 10:48:02: PROGRESS: processing sentence #200000\n",
      "INFO - 10:48:39: PROGRESS: processing sentence #300000\n",
      "INFO - 10:49:14: PROGRESS: processing sentence #400000\n",
      "INFO - 10:50:13: PROGRESS: processing sentence #500000\n",
      "INFO - 10:50:49: PROGRESS: processing sentence #600000\n",
      "INFO - 10:51:22: PROGRESS: processing sentence #700000\n",
      "INFO - 10:51:54: PROGRESS: processing sentence #800000\n",
      "INFO - 10:52:19: Ending the co-occurence count.\n",
      "INFO - 10:52:19: 18790479 total bigrams\n",
      "INFO - 10:52:19: Creating the SPPMI matrix\n",
      "INFO - 10:52:19: Context distribution smoothing with alpha=0.75\n",
      "INFO - 10:52:20: Negative sampling / Shifted PMI with k=5\n",
      "INFO - 10:54:19: SPPMI matrix created\n",
      "INFO - 10:54:19: 9743294 non-zero elements\n",
      "INFO - 10:54:19: Starting the SVD decomposition\n",
      "INFO - 10:56:09: Ending the SVD decomposition\n",
      "INFO - 10:56:09: 246248 word vector of dimension 100\n",
      "INFO - 10:56:13: Model created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build the model: 9.67 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "model_svd = SPPMI_SVD()\n",
    "model_svd.train(sentences, min_count=5, sample=1e-3,\n",
    "                window=5, context_alpha=0.75, negative=5,\n",
    "                size=100, filename='models/model_svd')\n",
    "print('Time to build the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's briefly explore this model as well:\n",
    "\n",
    "* which words are closest to *tweet*, *happy*, and *sad*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet\n",
      "[(0.8505446456842223, 'calling'), (0.8495776193862725, 'read'), (0.8495180397542714, 'tweets'), (0.8469429176027146, 'bye'), (0.8430300546680312, ';)')]\n",
      "\n",
      "happy\n",
      "[(0.945999497086144, 'birthday'), (0.880208664436888, 'b-day'), (0.8734960561571478, 'bday'), (0.8417066940938347, 'party'), (0.8306431474125364, \"mother's\")]\n",
      "\n",
      "sad\n",
      "[(0.9005389780325246, 'upset'), (0.8694543835106927, 'makes'), (0.8580330362656811, 'cool'), (0.8569899488119206, 'bad'), (0.8516815302520757, 'very')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in ['tweet', 'happy', 'sad']:\n",
    "    print(x)\n",
    "    print(model_svd.most_similar(x))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How similar are *sad* and *joy*? *Sad* and *unhappy*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.615120747879863"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svd.similarity('sad', 'joy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5916505460246356"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svd.similarity('sad', 'unhappy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the similarities and synonyms, SPPMI - SVD doesn't seem to do as well a job as Word2Vec. We will see if the word embeddings we obtained with SPPMI - SVD can still be used for Sentiment Analysis.\n",
    "\n",
    "Let's save the vectors into file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:57:44: Saved 246248 word vector under models/model_svd.vectors\n"
     ]
    }
   ],
   "source": [
    "model_svd.save_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of spaCy models from our word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using [spaCy](https://spacy.io/api/cli#init-model) to create easy and intuitive word-vector models. One advantage of using our word vectors through spaCy-like models, is that spaCy model API automatically averages the word vectors of a sentence for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spacy_model(filename):\n",
    "    \"\"\" Creates spaCy model out of a model's word vectors. \"\"\"\n",
    "    command = 'python -m spacy init-model en {} --vectors-loc {}.vectors'.format(filename, filename)\n",
    "\n",
    "    print('Starting command \\'' + command + '\\'')\n",
    "    res = os.system(command)\n",
    "\n",
    "    if res == 0:\n",
    "        print('Completed with exit code {}'.format(res))\n",
    "    else:\n",
    "        print('Completed in error with exit code {}'.format(res))\n",
    "        raise Exception('Bad exit code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* spaCy model for Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting command 'python -m spacy init-model en models\\model_w2v --vectors-loc models\\model_w2v.vectors'\n",
      "Completed with exit code 0\n"
     ]
    }
   ],
   "source": [
    "create_spacy_model('models\\model_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = spacy.load('models\\model_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.9360871e-01, -4.0373829e-01, -7.3135686e-01,  6.7814432e-02,\n",
       "        3.2670039e-01, -3.6968055e-01,  4.2483974e-01,  6.0680234e-01,\n",
       "        2.7229679e-01,  7.5300694e-02, -9.3267995e-01,  1.1516744e+00,\n",
       "       -2.1599710e-01,  9.2498976e-01, -8.6214191e-01,  1.4533650e+00,\n",
       "        1.8456541e+00,  4.0709034e-01,  4.8833296e-01,  8.5335189e-01,\n",
       "        5.8849347e-01,  6.3176751e-01,  3.0086210e-01, -8.8955039e-01,\n",
       "       -2.3232644e+00, -6.7330527e-01,  1.3408600e+00, -1.7199874e-02,\n",
       "       -9.6941453e-01, -7.6843578e-01, -1.3020439e+00,  6.4063293e-01,\n",
       "        2.6226482e-01,  6.3013635e-03, -2.2732913e-03, -1.5816294e+00,\n",
       "       -2.3162031e-01, -6.4014089e-01,  1.9306637e+00, -2.3000325e-01,\n",
       "        1.3733950e+00,  5.4681206e-01, -7.0206547e-01,  4.7222617e-01,\n",
       "        1.9982543e+00, -7.7410140e-03, -1.9335833e+00, -8.3441615e-02,\n",
       "        9.9696332e-01,  2.4098861e+00, -3.4839353e-01, -8.8258457e-01,\n",
       "       -4.0350989e-01,  9.7480059e-01,  2.9427424e-01,  9.2753959e-01,\n",
       "       -1.0028471e+00,  6.3145095e-01, -7.2773534e-01, -3.0623386e-02,\n",
       "        7.4123335e-01, -2.6117164e-01,  4.9768427e-01,  3.1397620e-01,\n",
       "        4.8684660e-01,  8.5301042e-01,  7.2921199e-01,  4.9818668e-01,\n",
       "       -5.8712590e-01,  4.2697981e-01, -6.4734705e-02, -8.1085026e-02,\n",
       "       -1.7973009e+00,  2.3272071e+00, -1.6685654e+00,  8.3501917e-01,\n",
       "        2.2145671e-01, -4.5928556e-02, -1.9442701e-01,  1.8550961e-01,\n",
       "       -7.7630466e-01,  1.2211943e-01, -7.0867740e-02, -1.3121268e+00,\n",
       "       -4.7877324e-01,  2.8354347e-01, -1.0501586e+00,  6.3968140e-01,\n",
       "        9.1646515e-02,  1.2046441e+00, -5.0537014e-01,  4.6106651e-01,\n",
       "       -6.6218114e-01,  1.5124289e+00, -1.0610751e+00,  1.1274394e-01,\n",
       "       -3.2535902e-01,  1.0598844e+00, -1.9445789e-01,  1.8570446e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v('I feel sad').vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* spaCy model for SPPMI - SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting command 'python -m spacy init-model en models\\model_svd --vectors-loc models\\model_svd.vectors'\n",
      "Completed with exit code 0\n"
     ]
    }
   ],
   "source": [
    "create_spacy_model('models\\model_svd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = spacy.load('models\\model_svd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07221159,  0.0020665 , -0.04702758,  0.07317644,  0.09699161,\n",
       "       -0.05983282, -0.09704677, -0.01771402, -0.02714226,  0.02673862,\n",
       "        0.00806751,  0.04758884,  0.03091562, -0.04543032, -0.00141869,\n",
       "        0.05984965, -0.05673602,  0.05264436, -0.02160857,  0.07892204,\n",
       "       -0.05177593,  0.0531452 ,  0.06102423, -0.06467202,  0.01398815,\n",
       "        0.03977588, -0.0472517 ,  0.04298294, -0.00842079, -0.03123913,\n",
       "       -0.04748407, -0.00665995, -0.06676573,  0.02728237,  0.02001343,\n",
       "        0.02803566,  0.09914891, -0.0108225 ,  0.04433878,  0.06577053,\n",
       "       -0.04147626, -0.02418843,  0.04766657,  0.00081633,  0.02670601,\n",
       "        0.05926756, -0.03076327,  0.00445091, -0.11256451, -0.03684159,\n",
       "        0.02856413, -0.01483583, -0.04542365, -0.00432092,  0.0112543 ,\n",
       "        0.0658531 , -0.01808496,  0.01440693, -0.02174714,  0.02151062,\n",
       "        0.06138566, -0.03465845,  0.00102009, -0.02446709,  0.00456469,\n",
       "       -0.04884902,  0.03167627,  0.02098353, -0.01028409,  0.0226131 ,\n",
       "        0.01541386, -0.01920778,  0.04638809, -0.01956601, -0.00306277,\n",
       "        0.00491748,  0.02688812, -0.04238101,  0.00814826, -0.05155239,\n",
       "        0.00851871, -0.01122072,  0.10267428,  0.03204434,  0.07767668,\n",
       "       -0.11854166,  0.00304944,  0.08479035,  0.05885055, -0.02833585,\n",
       "        0.0460388 ,  0.02080626, -0.03610764,  0.01274538,  0.00099004,\n",
       "        0.00092619, -0.00871008, -0.06894625,  0.01443019, -0.06821425],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd('This movie makes me happy !').vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's when spaCy built-in sentence average of word vectors comes in handy.\n",
    "\n",
    "* Training and testing sets vectorization for Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "train_vecs_w2v = [doc.vector for doc in w2v.pipe(x_train.tolist(), n_threads=-1, batch_size=50000)]\n",
    "print(\"{} mins\".format(round((time() - t) / 60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "test_vecs_w2v = [doc.vector for doc in w2v.pipe(x_test.tolist(), n_threads=-1, batch_size=50000)]\n",
    "print(\"{} mins\".format(round((time() - t) / 60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training and testing sets vectorization for SPPMI - SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "train_vecs_svd = [doc.vector for doc in svd.pipe(x_train.tolist(), n_threads=-1, batch_size=50000)]\n",
    "print(\"{} mins\".format(round((time() - t) / 60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "test_vecs_svd = [doc.vector for doc in svd.pipe(x_test.tolist(), n_threads=-1, batch_size=50000)]\n",
    "print(\"{} mins\".format(round((time() - t) / 60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "## Stochastic Gradient Descent  Classifier\n",
    "\n",
    "From [scikit-learn:](https://scikit-learn.org/stable/modules/sgd.html)\n",
    "\n",
    "> \"Stochastic Gradient Descent (SGD) is a simple yet very efficient approach to discriminative learning of linear classifiers under convex loss functions such as (linear) Support Vector Machines and Logistic Regression.\n",
    ">\n",
    "> SGD has been successfully applied to large-scale and sparse machine learning problems often encountered in text classification and natural language processing. Given that the data is sparse, the classifiers in this module easily scale to problems with more than 10^5 training examples and more than 10^5 features.\n",
    ">\n",
    "> The advantages of Stochastic Gradient Descent are:\n",
    "* Efficiency.\n",
    "* Ease of implementation (lots of opportunities for code tuning).\n",
    ">\n",
    "> The disadvantages of Stochastic Gradient Descent include:\n",
    "* SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "* SGD is sensitive to feature scaling.\"\n",
    "\n",
    "\n",
    "As stated by scikit-learn, Stochastic Gradient Descent Classifiers are very efficient and fast when it comes to train a model with 1 million or more data points, as we have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training of a Logistic Regression for Word2Vec word embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 238.77, NNZs: 81, Bias: -1.129978, T: 871198, Avg. loss: 0.715777\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 238.95, NNZs: 80, Bias: -1.085743, T: 1742396, Avg. loss: 0.533325\n",
      "Total training time: 2.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 239.02, NNZs: 83, Bias: -1.111631, T: 2613594, Avg. loss: 0.529996\n",
      "Total training time: 3.37 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 239.07, NNZs: 86, Bias: -1.065068, T: 3484792, Avg. loss: 0.528640\n",
      "Total training time: 4.38 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 239.11, NNZs: 87, Bias: -1.130737, T: 4355990, Avg. loss: 0.527944\n",
      "Total training time: 5.40 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 239.14, NNZs: 89, Bias: -1.063153, T: 5227188, Avg. loss: 0.527556\n",
      "Total training time: 6.40 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 239.16, NNZs: 85, Bias: -1.091336, T: 6098386, Avg. loss: 0.527111\n",
      "Total training time: 7.40 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 239.18, NNZs: 85, Bias: -1.065449, T: 6969584, Avg. loss: 0.526873\n",
      "Total training time: 8.41 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 239.19, NNZs: 88, Bias: -1.074759, T: 7840782, Avg. loss: 0.526726\n",
      "Total training time: 9.66 seconds.\n",
      "Convergence after 9 epochs took 9.67 seconds\n",
      "\n",
      "Time to train the model: 0.19 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "Model_w2v = SGDClassifier(loss='log', penalty='l1', verbose=2)\n",
    "Model_w2v.fit(train_vecs_w2v, y_train)\n",
    "print('\\nTime to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training of a Logistic Regression for SPPMI - SVD word embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 71.21, NNZs: 71, Bias: -0.059940, T: 871198, Avg. loss: 0.580348\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 73.35, NNZs: 70, Bias: -0.119230, T: 1742396, Avg. loss: 0.573776\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 74.57, NNZs: 69, Bias: -0.039965, T: 2613594, Avg. loss: 0.573397\n",
      "Total training time: 3.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 75.42, NNZs: 69, Bias: -0.013962, T: 3484792, Avg. loss: 0.573246\n",
      "Total training time: 4.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 76.07, NNZs: 69, Bias: -0.083402, T: 4355990, Avg. loss: 0.573144\n",
      "Total training time: 5.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 76.60, NNZs: 69, Bias: -0.045483, T: 5227188, Avg. loss: 0.573094\n",
      "Total training time: 6.16 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 77.04, NNZs: 69, Bias: -0.085731, T: 6098386, Avg. loss: 0.573041\n",
      "Total training time: 7.19 seconds.\n",
      "Convergence after 7 epochs took 7.19 seconds\n",
      "\n",
      "Time to train the model: 0.23 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "Model_svd = SGDClassifier(loss='log', penalty='l1', verbose=2)\n",
    "Model_svd.fit(X=train_vecs_svd, y=y_train)\n",
    "print('\\nTime to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which accuracies are we reaching on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec  Test Accuracy: 0.74\n",
      "SPPMI-SVD Test Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "print('Word2Vec  Test Accuracy: {:.2f}'.format(Model_w2v.score(test_vecs_w2v, y_test)))\n",
    "print('SPPMI-SVD Test Accuracy: {:.2f}'.format(Model_svd.score(test_vecs_svd, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For Word2Vec **74%**, not amazing but decent, especially with a simple linear model, no tuning, and minimal pre-processing of the text. \n",
    "* However, for SPPMI - SVD, **70%** is very close to the accuracy on the Word2Vec embeddings ! Let's look at other metrics to compare them fully.\n",
    "\n",
    "\n",
    "How are the [ROC curves and their corresponding AUC](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0).clf()\n",
    "\n",
    "# ROC curve and AUC for Word2Vec\n",
    "y_pred_w2v = Model_w2v.predict_proba(test_vecs_w2v)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_w2v)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=\"W2V embeddings, area={:.2f}\".format(roc_auc))\n",
    "\n",
    "# ROC curve and AUC for SPPMI - SVD\n",
    "y_pred_svd = Model_svd.predict_proba(test_vecs_svd)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_svd)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=\"SPPMI-SVD embeddings, area={:.2f}\".format(roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curves are very similar to each other and decent, the AUC for SPPMI - SVD is smaller though, 0.77 compared to 0.81.\n",
    "\n",
    "Let's have look a the two confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Word2Vec confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75    120415\n",
      "           1       0.69      0.75      0.72     97385\n",
      "\n",
      "    accuracy                           0.74    217800\n",
      "   macro avg       0.73      0.74      0.73    217800\n",
      "weighted avg       0.74      0.74      0.74    217800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_class_w2v = Model_w2v.predict(test_vecs_w2v)\n",
    "print(classification_report(y_class_w2v, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An F1-score of 0.74, that's more than ok!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SPPMI - SVD confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.71    116868\n",
      "           1       0.67      0.70      0.68    100932\n",
      "\n",
      "    accuracy                           0.70    217800\n",
      "   macro avg       0.70      0.70      0.70    217800\n",
      "weighted avg       0.70      0.70      0.70    217800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_class_svd = Model_svd.predict(test_vecs_svd)\n",
    "print(classification_report(y_class_svd, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the precision, recall, f1-score are overall decent, they are lower than for Word2Vec, but only by a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief recap of what we've done:\n",
    "1. We used a 1.6 million tweets dataset to create both a Word2Vec and a SPPMI - SVD model\n",
    "2. Using these models, we transformed the tweets into vectors\n",
    "3. With these vectors in hand, we fed them to linear classifiers to predict the sentiment of each tweet\n",
    "4. We compared the classification results obtained by Word2Vec and SPPMI - SVD word embeddings\n",
    "\n",
    "We used both Word2Vec and SPPMI - SVD in their default mode, the tweets received only a light preprocessing, and we stuck to linear classifiers without any tuning. Still, in both cases, we got decent classification performance. Even better, SPPMI - SVD was very close to Word2Vec in term of Sentiment classification results.\n",
    "\n",
    "**In the end, for this Sentiment Analysis task, SPPMI - SVD provides a decent alternative to Word2Vec**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgement\n",
    "\n",
    "* My implementation of SPPMI - SVD is very simple, if it were to be optimized (Numpy vectorization, multiprocessing or Cython code), it should produce word embeddings much faster than Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* [1]. Mikolov et al. [*Efficient Estimation of Word Representations in Vector Space*](https://arxiv.org/pdf/1301.3781.pdf) \n",
    "* [2]. Mikolov et al. [*Distributed Representations of Words and Phrases and their Compositionality*](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "* [3].  Omer Levy and Yoav Goldberg [*Neural Word Embedding as Implicit Matrix Factorization*](https://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf)\n",
    "* [4]. Ahmed Besbes [*Sentiment Analysis on twitter using word2vec and keras*](https://ahmedbesbes.com/sentiment-analysis-on-twitter-using-word2vec-and-keras.html)\n",
    "* [5]. Sebastian Ruder [*On word embeddings - Part 3: The secret ingredients of word2vec*](http://ruder.io/secret-word2vec/)\n",
    "* [6]. Chris Moody [*Stop Using Word2Vec*](https://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
